GWAS Example
========================================================
author: Emily Flynn
date: 8/24/2020
transition: none
width: 1680
height: 1050

Learning objectives
========================================================
- preprocess a large messy dataset
- use an R package to make manhattan plots
- use external code to make a miami plot


Background
========================================================
- UK Biobank
- Sex differences
- Sex differences in testosterone genetics
[cite myself https://www.biorxiv.org/content/10.1101/837021v1]

Genome-wide association study (GWAS)

Dataset - GWAS summary statistics
========================================================
First, we're going to read in summary statistics for testosterone. For GWAS, the summary statistics consist of the BETA, SE, and P (pvalue) for the association between a particular genetic variant (ID, rs...) at a specific location in the genome (given here by the chromosome and position). 

These files were generated using plink. Read in the data and take a look at it. Also try using `summary()` - what do you notice about the data? What about missingness?
```{r, message=FALSE}
library('tidyverse')
# install.packages('vroom')
library('vroom') # Note - we could use "read_tsv" to read in the data -- however, it's kind of big, so let's try vroom (a new tidyverse package) that speeds up data read in. Note that the data has a .gz 
testosterone_f <- vroom("/Users/eflynn/Documents/EMILY/Stanford/Lab/AltmanLab/projects/BMM_project/test/ukbb_testosterone_sumstats_females.txt.gz")
head(testosterone_f, 3)
```

Do the same with the `sumstats_males` file.

How does GWAS work?
========================================================

The idea behind GWAS is that we're fitting a ton of models, one for each variant, in order to identify variants is associated with a trait of interest. At every location (except for most of the X and Y chromosomes), people have two  alleles. Here we use an additive model (given by "ADD"), where for each person at that particular location we have a 0, 1, 2 for the number of copies of the alternate allele. There are other models that consider recessive/dominant or multiplicative effects. By fitting the model across many individuals, we get a coefficient (or $beta$) for the variant. We also get a standard error for that $beta$. 

 $$ trait \~ beta*num\_copies\_alternate\_allele $$

After fitting tons of these models (in theory as many as 3 million, one for each variant - in practice usually a factor below that), we then want to test whether the variants are associated with the trait, in this case testosterone. To do so, we test whether the coefficient $beta$ is significantly different than zero, and we get a p-value describing this. For very low p-values, we reject the null hypothesis that $beta$ is zero, or that the variant is not associated with the trait. Because we are doing so many tests, we use a very low threshold to call something "genome-wide significant" (the standard is  $p < 5 x 10^{-8}$).

Looking at GWAS data
========================================================

Use tidyverse to filter for the variants under the genome-wide significance threshold.
What is the lowest p-value? What is the highest absolute coefficient (beta)?
```{r}
# solution
testosterone_f %>% filter(P < (5*10^(-8))) %>% arrange(desc(abs(BETA))) %>% head(5)
```


Plotting GWAS data with qqman
========================================================
left: 25%

The standard way to visualize GWAS data is to create a Manhattan plot.

```{r}
#install.packages('qqman')
library('qqman')
manhattan(gwasResults)
```

***

In order to use qqman, we'll have to figure out how to get our data into the manhattan function. Try `?manhattan` and then also take a look at the GWAS results -- how does it look different from our data? What are the labels and types of the important columns? 
```{r}
gwasResults %>% as_tibble() %>% head(2)
testosterone_f %>% head(3)
```

Exercise - plotting our data with qqman
========================================================

What modifications do you have to make to the data to be able to plot? Let's start with a smaller version of the dataset -- we'll come back to why in a second. Now work in groups to plot the data.
```{r}
testosterone_sm <- testosterone_f %>% sample_n(10000)

# answer key
t2 <- testosterone_sm %>%
  filter(!is.na(P)) %>%
  rename("CHR"="#CHROM", "BP"="POS", "SNP"="ID") %>%
  mutate(CHR=case_when(
    CHR=="X" ~ 23,
    CHR=="XY" ~ 24,
    TRUE ~ as.numeric(CHR)
  ))

```

Plotting large datasets
========================================================

We suggested starting with a smaller version of the dataset because if you try to plot the data - you'll notice it starts to hang.
```{r}
#manhattan(t2)
```

Use "Ctrl-C" or press the "STOP" button or try "Session" > "Interrupt R". These are all good ways to stop a command when it's taking too long.

Why did this happen? Take a look at the number of rows in the example versus our dataset using `nrow()`. It's helpful to get an idea of how different the data are in size.

Plotting large datasets - part 2
========================================================

We used `sample_n()` to do a quick check to see if you can plot the data now:
```{r}
#t2_sm <- t2 %>% sample_n(10000)
#manhattan(t2_sm)
```

What are the variants with smallest pvalues in `t2_sm`? Does it match the full dataset?

Downsampling for visualization
========================================================

Typically, when we downsample for visualization purposes, we want to downsample the data that we're less interested in - e.g. the variants that are not associated and have high p-values. For visualization purposes it looks like $p = 10^(-3)$ is a reasonable cutoff.

To do this, use tidyverse to divide the dataset into two parts based on p-value. Then use `sample_n()` to grab 10% of the high-pvalue variants. Put the data back together (hint: `bind_rows()`) and plot again with qqman. Does this work?
```{r}
# answer key:
low_p <- t2 %>%
  filter(P < (10**-3))
high_p <- t2 %>%
  filter(P >= (10**-3))
t3 <- high_p %>% sample_n(floor(nrow(high_p)*0.1)) %>%
  bind_rows(low_p)
```

Truncating the data for visualization
========================================================
You'll notice now that when you plot, you can do it in a reasonable time but the y axis scale now goes very high, which makes it hard to see. 

```{r}
manhattan(t3)
```

***

For visualization, it is common to truncate the data so it solves this, e.g. make all p-values < $10^(-30)$ equal to $10^-30$. Use a mutate to do this and visualize again. Does this help? Can you tell that we've downsampled the data?
```{r}
# solution
t4 <- t3 %>%
  mutate(P=ifelse(P<(10**(-30)),10**(-30), P ))
manhattan(t4)
```

Functions
========================================================
Now we want to do the same thing we just did with the testosterone GWAS summary statistics from males. 

We could copy and paste everything - but there is a better way!

Write a function that takes a table with summary stats and performs these pre-processing steps (dealing with column names, filtering NAs, converting to numeric, downsampling, etc) to get it ready for a manhattan plot. Check that it produces the same output (within random sampling) on the female testosterone sumstats data, then apply to the male data.
```{r}
preprocess_gwas_for_manhattan <- function(sum_stats){
  # 1. remove NAs
  # 2. fix column names
  # 3. fix data types
  # 4. downsample for viz
  # 5. truncate
}
```

Once you've processed the data, make both manhattan plots!

Making the Manhattan plot fancier
========================================================
Take a look at the manhattan plot vignette and try a couple things: https://cran.r-project.org/web/packages/qqman/vignettes/qqman.html. 

Miami plot
========================================================
A Miami plot is two Manhattan plots opposite each other. It allows for comparison of the datasets.

I initially googled "how to make a miami plot R" and tired a few solutions, but wound up wanting more control. So instead I googled "how to make a manhattan plot ggplot" and adapted the code for a Miami plot. 

The code is adapted from:
https://danielroelfs.com/blog/how-i-create-manhattan-plots-using-ggplot/
```{r}
convert_to_bp <- function(dat){
  # this sets up the X axis scale with base pairs
  dat$BPcum <- 0
  s <- 0
  nbp <- c()

  for (i in 1:length(unique(dat$CHR))){
    nbp[i] <- max(dat[dat$CHR == i,]$BP)
    dat[dat$CHR == i,"BPcum"] <- dat[dat$CHR == i,"BP"] + s
    s <- s + nbp[i]
  }
  return(dat)
}

prep_miami_dat <-  function(dat1, dat2) {
  dat1.2 <- convert_to_bp(dat1)
  dat2.2 <- convert_to_bp(dat2)

  dat1.3 <- dat1.2 %>% mutate(log10P=-log10(P))
  dat2.3 <- dat2.2 %>% mutate(log10P=log10(P))

  gwas_dat <- dat1.3 %>% 
    bind_rows(dat2.3) %>% 
    filter(!is.na(P)) %>% 
    mutate(point_grp=((CHR %% 2)==0)) %>%
    mutate(CHR=case_when(
      CHR == 23 ~ "X",  
      CHR == 24  ~"XY",
      CHR == 25 ~ "Y",
      TRUE ~ as.character(CHR))) 
  
  return(gwas_dat)
} 
  
make_miami_plot <- function(gwas_dat, sig=5*(10**-8), label1="", label2=""){

  # calculate the axis 
  axis.set <- gwas_dat %>% 
    group_by(CHR) %>% 
    summarize(center = (max(BPcum) + min(BPcum)) / 2)
  
  gwas_dat %>% 
    ggplot( aes(x=BPcum, y=log10P)) +
    # alternating colors for variants based on even/odd chromosome
    geom_point(aes(color=as.factor(point_grp)), alpha = 0.3) +
    scale_color_manual(values=c( "gray79", "gray46")) +
    
    # draw lines at y=0 and genome-wide sig for reference
    geom_hline(yintercept = 0, color = "black")+ 
    geom_hline(yintercept = -log10(sig), color = "grey40", linetype = "dashed") +
    geom_hline(yintercept = log10(sig), color = "grey40", linetype = "dashed") +
    # axes
    labs(x = NULL, y = "-log10(p)") + 
    # adjust the X axis scale
    scale_x_continuous(label = axis.set$CHR, breaks = axis.set$center) +
    
    # correct Y axis labels
    scale_y_continuous(breaks=c(-30, -20, -10, 0, 10, 20, 30), label=c("-30"=">30", "-20"="20", "-10"="10", "0"="0", "10"="10", "20"="20", "30"=">30"))+
    
    # adding labels for each dataset
    #geom_text(x=0, y=25, label=label1)+
    #geom_text(x=0, y=-25, label=label2)+
    
    # clean up the background and labels
    theme_bw()+
    theme(
      legend.position = "none",
      panel.border = element_blank(),
      panel.grid.major.x = element_blank(),
      panel.grid.minor.x = element_blank(),
      axis.text.x = element_text(angle = 60, size = 8, vjust = 0.5))
  
}


```

Making a Miami plot
========================================================

Now let's use the functions about and make a Miami plot
```{r}
gwas_dat <- prep_miami_dat(t4, t4)
gwas_dat %>%
  make_miami_plot(label1="Females", label2="Males")

```


Highlighting points
========================================================

Let's make the significant variants stand out. The nice thing is that we have a ggplot object so we can just add to it. We can do this by adding points. An easy way to add these points is to add new data objects for these geoms.
```{r}
gwas_dat %>%
  make_miami_plot()+
   geom_point(data=gwas_dat %>% 
                 filter(log10P > 8), col="blue")+
   geom_point(data=gwas_dat %>% 
                 filter(log10P < -8), col="red")
```


Adding labels
========================================================
As part of my analysis of these data, we used a Bayesian Mixture Model to identify subsets of variants that showed shared and sex-specific effects. The details aren't important for this, let's just say that we want to highlight these variants in the plot.

First, let's read in these data. They're in three sheets.
```{r}
f_spec <- read_csv("/Users/eflynn/Documents/EMILY/Stanford/Lab/AltmanLab/projects/BMM_project/out_tables/bio_m2_fspec.csv") 
#m_spec <- read_csv("out_tables/bio_m2_mspec.csv")
#shared <- read_csv("out_tables/bio_m2_shared.csv")
head(f_spec,4)
```

Filter these data so we're only looking at the Testosterone variants.
```{r}
f_spec_t <- f_spec %>% filter(trait=="Testosterone")
```

Highlighting points -- part 2
========================================================
left: 60%

Then we're going to need to do a type of "join" with the "gwas_dat". First - what column are we joining by? You will have to use the `by=c("id1"="id2")` syntax. Second - what columns do we want in the output? Use a select and set it up so that this only adds two columns "Consequence" and "GENE" to the table.

```{r}
f_spec_filt <- gwas_dat %>% 
  inner_join(f_spec_t %>% 
               select(ID, GENE, Consequence), by=c("SNP"="ID"))

head(f_spec_filt, 4)
```

*** 
```{r}
gwas_dat %>%
  make_miami_plot()+
   geom_point(data=f_spec_filt, col="blue")

```

Repeat this for each of the types of variants.

Adding labels for genes
=================
You might be interested in looking at what genes are attached to the significant variants. We can use the variant tables and the package `ggrepel` to add these.

For a first pass, it can be helpful to sample only a subset of variants so that we don't get too crowded with labels.
```{r}
#install.packages('ggrepel')
library(ggrepel)
gwas_dat %>%
  make_miami_plot()+
  geom_point(data=f_spec_filt, col="blue")+
  geom_label_repel(data=f_spec_filt %>% sample_n(50), aes(label=GENE), size=2) 

```



Miami Plot Exercises 
==================================

1. Modify this code so that instead of sampling random genes, we are getting only the missense variants. You will use the `Consequence` field.

2. Modify this again so that we only label the top 20 most significant variants.  
```{r}
# solution
gwas_dat %>%
  make_miami_plot()+
  geom_point(data=f_spec_filt, col="blue")+
  geom_label_repel(data=f_spec_filt %>% 
                     arrange(desc(log10P)) %>% head(30),
                   aes(label=GENE), size=2) 
```

3. Add in the m-spec and shared variants. Note - you may have to do something a little different to label variants these variants on either side of the axis. 
